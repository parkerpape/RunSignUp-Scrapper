{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcce81a-9605-4d81-a930-daa054b056af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🏁 RunSignUp Race Scraper\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# ----------------------\n",
    "# 1. Helper Functions\n",
    "# ----------------------\n",
    "\n",
    "def get_driver():\n",
    "    \"\"\"Initialize a headless Chrome driver.\"\"\"\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    return webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "def extract_race_info(row, race_type):\n",
    "    \"\"\"Extract title, link, location, and date info from a single race row.\"\"\"\n",
    "    try:\n",
    "        title_element = row.find_element(By.CSS_SELECTOR, \"div.flex-1 > a\")\n",
    "        title = title_element.text.strip()\n",
    "        race_link = title_element.get_attribute(\"href\")\n",
    "    except:\n",
    "        title, race_link = \"N/A\", \"N/A\"\n",
    "\n",
    "    try:\n",
    "        date = row.find_element(By.CSS_SELECTOR, \"td.ta-left.fs-sm-2\").text.strip()[4:]\n",
    "    except:\n",
    "        date = \"N/A\"\n",
    "\n",
    "    try:\n",
    "        location_span = row.find_element(By.CSS_SELECTOR, \"td.ta-left.fs-sm-2 > span > span\")\n",
    "        location_text = location_span.text.strip()\n",
    "        if \",\" in location_text:\n",
    "            city, state_country = location_text.rsplit(\",\", 1)\n",
    "            state, _, country = state_country.strip().partition(\" \")\n",
    "        else:\n",
    "            city, state, country = \"N/A\", \"N/A\", \"N/A\"\n",
    "    except:\n",
    "        city, state, country = \"N/A\", \"N/A\", \"N/A\"\n",
    "\n",
    "    try:\n",
    "        postal_code_element = row.find_element(By.CSS_SELECTOR, \"div.postalCode\")\n",
    "        postal_code = postal_code_element.text.strip()[:6] if postal_code_element else \"N/A\"\n",
    "    except:\n",
    "        postal_code = \"N/A\"\n",
    "\n",
    "    return {\n",
    "        \"Race Title\": title,\n",
    "        \"Race Link\": race_link,\n",
    "        \"City\": city,\n",
    "        \"State\": state,\n",
    "        \"Country\": country,\n",
    "        \"Postal Code\": postal_code,\n",
    "        \"Date\": date,\n",
    "        \"Race Type\": race_type\n",
    "    }\n",
    "\n",
    "def scrape_races(race_type_list, num_pages=3, num_items=250):\n",
    "    \"\"\"Scrape races from RunSignUp for given race types and page counts.\"\"\"\n",
    "    race_data = []\n",
    "    for race_type in race_type_list:\n",
    "        for page in range(1, num_pages + 1):\n",
    "            driver = get_driver()\n",
    "            url = f\"https://runsignup.com/Races?name=&eventType={race_type}&radius=5&zipcodeRadius=&country=US&state=&distance=&max_distance=&units=K&start_date=2025-02-03&end_date=&num={num_items}&page={page}\"\n",
    "            driver.get(url)\n",
    "            time.sleep(2)\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2)\n",
    "\n",
    "            try:\n",
    "                race_rows = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_all_elements_located((By.XPATH, \"//tr\"))\n",
    "                )\n",
    "            except:\n",
    "                driver.quit()\n",
    "                continue\n",
    "\n",
    "            for row in race_rows:\n",
    "                try:\n",
    "                    race_info = extract_race_info(row, race_type)\n",
    "                    if race_info[\"Race Title\"] != \"N/A\":\n",
    "                        race_data.append(race_info)\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            driver.quit()\n",
    "    return pd.DataFrame(race_data)\n",
    "\n",
    "# ----------------------\n",
    "# 2. Run Scraper\n",
    "# ----------------------\n",
    "\n",
    "race_types = [\"triathlon\", \"duathlon\", \"bike_race\", \"swim\", \"swim_run\", \"aqua_bike\"]\n",
    "df = scrape_races(race_types)\n",
    "\n",
    "# ----------------------\n",
    "# 3. Export Data\n",
    "# ----------------------\n",
    "\n",
    "output_path = \"data/race_listings_RunSignUp.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Scraping complete. Data saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
